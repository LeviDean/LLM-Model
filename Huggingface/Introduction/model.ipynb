{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:8889\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:8889\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 828/828 [00:00<00:00, 9.24MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 156M/156M [00:21<00:00, 7.14MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./download_models/hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model mannually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone \"https://huggingface.co/hfl/rbt3\"\n",
    "# !git lfs clone \"https://huggingface.co/hfl/rbt3\" --include=\"*.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"./download_models/hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"./download_models/hfl/rbt3\",\n",
       "  \"architectures\": [\n",
       "    \"BertModel\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.33.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"./download_models/hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"./download_models/hfl/rbt3\", output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.output_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 19.0/19.0 [00:00<00:00, 40.1kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 1.22MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 269k/269k [00:00<00:00, 2.62MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 4.72kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 249kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 3457, 2682, 8013,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"弱小的我也有大梦想！\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[4.7840e-01, 3.7087e-04, 1.6194e-04,  ..., 1.4241e-04,\n",
       "            4.1823e-04, 5.1813e-01],\n",
       "           [4.8793e-03, 8.4205e-02, 1.0109e-01,  ..., 1.6317e-01,\n",
       "            1.3569e-01, 3.8025e-03],\n",
       "           [1.6934e-02, 9.4463e-02, 1.6830e-01,  ..., 1.0398e-01,\n",
       "            2.0319e-01, 3.0596e-03],\n",
       "           ...,\n",
       "           [2.6368e-02, 8.2262e-02, 4.2802e-02,  ..., 1.0264e-01,\n",
       "            2.0798e-01, 1.0292e-02],\n",
       "           [6.1473e-02, 5.6857e-02, 4.2318e-02,  ..., 7.1384e-02,\n",
       "            3.6086e-01, 2.4631e-02],\n",
       "           [4.6689e-01, 8.9996e-04, 4.2500e-04,  ..., 2.7257e-04,\n",
       "            1.1381e-03, 5.2718e-01]],\n",
       " \n",
       "          [[9.8990e-01, 2.5772e-05, 2.0234e-04,  ..., 5.2056e-05,\n",
       "            1.0738e-03, 3.7625e-03],\n",
       "           [1.7755e-02, 1.2910e-04, 9.8209e-01,  ..., 2.9791e-10,\n",
       "            2.1697e-06, 2.7124e-07],\n",
       "           [2.1831e-02, 9.7443e-01, 1.5326e-04,  ..., 1.2469e-08,\n",
       "            7.8246e-08, 1.0876e-04],\n",
       "           ...,\n",
       "           [1.1508e-02, 3.0013e-09, 4.1517e-08,  ..., 1.5005e-04,\n",
       "            3.2545e-03, 1.7668e-04],\n",
       "           [2.4576e-01, 2.9066e-06, 6.4727e-08,  ..., 3.6932e-03,\n",
       "            4.7574e-04, 7.4964e-01],\n",
       "           [5.9086e-01, 1.3709e-07, 7.4794e-05,  ..., 2.6531e-05,\n",
       "            4.0552e-01, 2.6671e-03]],\n",
       " \n",
       "          [[1.6501e-01, 9.1225e-02, 2.5748e-02,  ..., 5.6965e-02,\n",
       "            9.7241e-02, 2.3059e-01],\n",
       "           [4.7152e-01, 3.2132e-01, 3.1023e-02,  ..., 8.9475e-03,\n",
       "            1.6842e-02, 9.4982e-02],\n",
       "           [4.8925e-01, 1.7736e-01, 1.9220e-01,  ..., 4.7800e-03,\n",
       "            1.3740e-02, 6.2175e-02],\n",
       "           ...,\n",
       "           [1.5545e-01, 6.1267e-02, 5.8145e-02,  ..., 6.8622e-02,\n",
       "            2.9527e-02, 2.9667e-02],\n",
       "           [5.5325e-02, 4.2133e-02, 2.3946e-02,  ..., 4.4306e-02,\n",
       "            8.8572e-02, 8.7771e-02],\n",
       "           [3.6468e-02, 3.9798e-02, 4.4089e-02,  ..., 8.2621e-02,\n",
       "            1.4462e-01, 1.2662e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[7.0319e-01, 2.1875e-02, 4.0400e-02,  ..., 2.3610e-02,\n",
       "            2.3715e-02, 7.4948e-02],\n",
       "           [4.0515e-01, 3.2106e-01, 1.1058e-02,  ..., 1.2410e-02,\n",
       "            1.7615e-02, 1.0445e-01],\n",
       "           [5.8258e-01, 5.5240e-03, 5.3974e-03,  ..., 1.7208e-02,\n",
       "            2.5468e-02, 2.7251e-01],\n",
       "           ...,\n",
       "           [3.7059e-01, 4.3855e-02, 4.8776e-02,  ..., 2.4265e-01,\n",
       "            2.1269e-02, 7.7568e-02],\n",
       "           [1.2533e-01, 1.6208e-02, 3.0249e-02,  ..., 2.5662e-02,\n",
       "            4.0757e-01, 2.9812e-01],\n",
       "           [4.2679e-01, 4.2644e-02, 8.9271e-02,  ..., 1.3507e-02,\n",
       "            2.0495e-02, 1.4134e-01]],\n",
       " \n",
       "          [[9.7357e-01, 5.4136e-03, 3.0843e-03,  ..., 1.6786e-03,\n",
       "            2.3268e-03, 5.4027e-03],\n",
       "           [7.9612e-03, 7.2660e-02, 4.8077e-01,  ..., 4.1847e-03,\n",
       "            1.9911e-03, 6.7627e-03],\n",
       "           [1.4957e-03, 7.2041e-03, 1.7663e-02,  ..., 6.2025e-04,\n",
       "            4.2359e-03, 2.2025e-03],\n",
       "           ...,\n",
       "           [1.7129e-03, 4.9460e-04, 1.8233e-04,  ..., 6.1111e-03,\n",
       "            8.0681e-01, 1.7855e-01],\n",
       "           [2.0596e-02, 1.4022e-03, 1.1201e-03,  ..., 7.0329e-03,\n",
       "            1.0126e-01, 8.6120e-01],\n",
       "           [9.9354e-01, 6.1979e-05, 1.0303e-04,  ..., 2.0507e-04,\n",
       "            6.5383e-04, 5.1244e-03]],\n",
       " \n",
       "          [[4.2150e-01, 2.4260e-02, 1.9585e-02,  ..., 1.5905e-02,\n",
       "            3.2343e-02, 3.2890e-01],\n",
       "           [7.5474e-01, 1.1008e-01, 2.2799e-03,  ..., 4.7718e-03,\n",
       "            1.6809e-02, 6.7962e-03],\n",
       "           [4.3970e-02, 9.3117e-01, 6.5203e-03,  ..., 1.7745e-04,\n",
       "            1.1036e-03, 1.4444e-03],\n",
       "           ...,\n",
       "           [4.3447e-02, 1.1219e-03, 7.6249e-05,  ..., 2.7540e-02,\n",
       "            1.1937e-02, 6.7831e-03],\n",
       "           [3.4735e-01, 1.1213e-02, 1.3291e-02,  ..., 2.7917e-01,\n",
       "            1.3353e-01, 5.0572e-02],\n",
       "           [7.1003e-02, 1.5132e-03, 7.3036e-04,  ..., 2.2069e-02,\n",
       "            3.9020e-01, 5.0058e-01]]]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[[[4.3653e-01, 1.2017e-02, 5.9486e-03,  ..., 6.0889e-03,\n",
       "            6.2510e-02, 4.1911e-01],\n",
       "           [4.9485e-01, 1.4810e-02, 3.5573e-03,  ..., 2.6525e-06,\n",
       "            7.7276e-03, 4.7143e-01],\n",
       "           [1.3883e-02, 9.7162e-01, 1.4196e-05,  ..., 1.7454e-07,\n",
       "            8.6182e-06, 1.3725e-02],\n",
       "           ...,\n",
       "           [3.9525e-02, 7.2212e-06, 4.0403e-06,  ..., 6.8149e-06,\n",
       "            2.1746e-03, 3.7589e-02],\n",
       "           [3.7276e-01, 8.1322e-04, 4.1047e-04,  ..., 1.7777e-01,\n",
       "            4.8129e-02, 3.6578e-01],\n",
       "           [4.3777e-01, 1.1416e-02, 5.8509e-03,  ..., 5.9089e-03,\n",
       "            6.3776e-02, 4.2000e-01]],\n",
       " \n",
       "          [[4.6678e-01, 1.0235e-02, 6.1202e-03,  ..., 6.2378e-03,\n",
       "            1.0923e-02, 4.4965e-01],\n",
       "           [2.9057e-01, 1.4343e-02, 1.1761e-02,  ..., 3.3617e-02,\n",
       "            1.1928e-01, 2.9151e-01],\n",
       "           [2.3338e-01, 2.3156e-02, 8.7420e-03,  ..., 6.2520e-02,\n",
       "            1.5599e-01, 2.3423e-01],\n",
       "           ...,\n",
       "           [3.0643e-01, 2.5059e-02, 1.2080e-02,  ..., 3.9024e-02,\n",
       "            1.5327e-01, 3.0960e-01],\n",
       "           [1.2985e-01, 2.9326e-02, 1.4902e-02,  ..., 9.5539e-02,\n",
       "            2.5447e-01, 1.3206e-01],\n",
       "           [4.6893e-01, 9.5607e-03, 5.7683e-03,  ..., 5.9750e-03,\n",
       "            1.0103e-02, 4.5207e-01]],\n",
       " \n",
       "          [[4.9365e-01, 4.6236e-03, 4.0628e-03,  ..., 1.9692e-03,\n",
       "            4.7649e-03, 4.5183e-01],\n",
       "           [4.0014e-01, 2.0960e-01, 9.1869e-03,  ..., 1.3033e-03,\n",
       "            6.6394e-04, 3.6989e-01],\n",
       "           [3.9738e-01, 1.1984e-01, 8.2242e-02,  ..., 1.2187e-03,\n",
       "            2.4011e-03, 3.7076e-01],\n",
       "           ...,\n",
       "           [2.4969e-01, 4.7297e-03, 2.8019e-04,  ..., 7.1960e-02,\n",
       "            4.7626e-03, 2.3028e-01],\n",
       "           [2.5165e-01, 1.1145e-03, 1.3995e-03,  ..., 1.8613e-03,\n",
       "            4.7934e-01, 2.3994e-01],\n",
       "           [4.9327e-01, 4.8001e-03, 4.1925e-03,  ..., 2.0644e-03,\n",
       "            4.7635e-03, 4.5095e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[4.5285e-01, 9.8046e-03, 1.9008e-02,  ..., 1.4504e-02,\n",
       "            2.5172e-02, 4.2710e-01],\n",
       "           [2.7714e-01, 1.5313e-02, 2.6586e-02,  ..., 1.8827e-02,\n",
       "            1.9736e-02, 2.7695e-01],\n",
       "           [2.5708e-01, 7.3269e-03, 1.1370e-02,  ..., 1.5365e-02,\n",
       "            2.2514e-02, 2.6464e-01],\n",
       "           ...,\n",
       "           [4.4378e-01, 2.6481e-03, 2.3780e-03,  ..., 2.4616e-02,\n",
       "            4.9823e-02, 4.5435e-01],\n",
       "           [4.2933e-01, 1.6639e-02, 7.7778e-03,  ..., 1.6536e-02,\n",
       "            4.9764e-02, 4.2995e-01],\n",
       "           [4.5464e-01, 9.4518e-03, 1.8229e-02,  ..., 1.3868e-02,\n",
       "            2.4021e-02, 4.2919e-01]],\n",
       " \n",
       "          [[4.9040e-01, 4.7597e-03, 2.2697e-03,  ..., 1.4708e-03,\n",
       "            5.1065e-03, 4.6151e-01],\n",
       "           [4.4746e-01, 1.8176e-02, 1.2351e-02,  ..., 4.3363e-03,\n",
       "            9.6561e-03, 4.4103e-01],\n",
       "           [3.5675e-01, 4.1090e-02, 2.7275e-02,  ..., 1.2361e-02,\n",
       "            3.0071e-02, 3.4211e-01],\n",
       "           ...,\n",
       "           [1.8479e-01, 5.4278e-02, 3.6304e-02,  ..., 1.0251e-02,\n",
       "            8.2401e-02, 1.8141e-01],\n",
       "           [1.3622e-01, 5.0552e-02, 4.2730e-02,  ..., 1.3541e-02,\n",
       "            9.1346e-02, 1.3696e-01],\n",
       "           [4.8996e-01, 4.8204e-03, 2.2924e-03,  ..., 1.5024e-03,\n",
       "            5.0243e-03, 4.6148e-01]],\n",
       " \n",
       "          [[4.7184e-01, 6.5952e-03, 1.4942e-02,  ..., 2.0032e-03,\n",
       "            8.9569e-03, 4.5821e-01],\n",
       "           [2.8745e-01, 6.4402e-02, 5.5145e-02,  ..., 5.8005e-02,\n",
       "            3.4206e-02, 2.8082e-01],\n",
       "           [3.6048e-01, 8.8081e-02, 3.8540e-02,  ..., 1.2227e-02,\n",
       "            1.3103e-02, 3.4988e-01],\n",
       "           ...,\n",
       "           [2.8444e-01, 2.5244e-01, 1.4736e-02,  ..., 8.4384e-03,\n",
       "            1.0795e-02, 2.8038e-01],\n",
       "           [2.2920e-01, 8.9625e-02, 2.8974e-02,  ..., 1.2092e-02,\n",
       "            3.2623e-02, 2.2609e-01],\n",
       "           [4.7172e-01, 6.4383e-03, 1.5023e-02,  ..., 1.9758e-03,\n",
       "            8.8361e-03, 4.5832e-01]]]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[[[3.2780e-01, 2.6365e-02, 3.2871e-02,  ..., 9.6133e-03,\n",
       "            1.0898e-01, 3.2316e-01],\n",
       "           [4.5742e-01, 3.5140e-02, 2.2830e-02,  ..., 2.0939e-03,\n",
       "            4.4799e-03, 4.5110e-01],\n",
       "           [4.8155e-01, 1.6324e-02, 9.9996e-03,  ..., 1.1973e-03,\n",
       "            3.4325e-03, 4.7338e-01],\n",
       "           ...,\n",
       "           [2.7153e-01, 6.4185e-02, 2.8571e-02,  ..., 4.9459e-03,\n",
       "            6.7410e-03, 2.6692e-01],\n",
       "           [1.8439e-01, 3.0287e-02, 2.7450e-02,  ..., 1.5050e-02,\n",
       "            7.3344e-02, 1.8221e-01],\n",
       "           [3.2881e-01, 2.6313e-02, 3.2750e-02,  ..., 9.6148e-03,\n",
       "            1.0816e-01, 3.2417e-01]],\n",
       " \n",
       "          [[1.8750e-02, 6.2589e-02, 2.2339e-02,  ..., 5.5634e-02,\n",
       "            3.3249e-01, 1.8649e-02],\n",
       "           [3.1858e-01, 8.1700e-02, 2.1848e-01,  ..., 6.8917e-03,\n",
       "            1.1892e-03, 3.1426e-01],\n",
       "           [8.9934e-02, 8.1036e-01, 3.1089e-03,  ..., 8.8777e-05,\n",
       "            1.2451e-04, 8.9184e-02],\n",
       "           ...,\n",
       "           [4.2126e-01, 9.0581e-03, 1.5826e-03,  ..., 6.9298e-03,\n",
       "            5.4295e-03, 4.1756e-01],\n",
       "           [8.6953e-02, 1.5984e-01, 1.7643e-02,  ..., 3.6727e-01,\n",
       "            2.2709e-02, 8.6116e-02],\n",
       "           [1.8879e-02, 6.2910e-02, 2.2460e-02,  ..., 5.5693e-02,\n",
       "            3.3281e-01, 1.8778e-02]],\n",
       " \n",
       "          [[4.4325e-01, 1.9266e-03, 7.8245e-04,  ..., 1.6809e-03,\n",
       "            8.7054e-02, 4.4051e-01],\n",
       "           [4.3983e-01, 3.2083e-02, 3.4782e-02,  ..., 4.1581e-03,\n",
       "            7.0871e-04, 4.3195e-01],\n",
       "           [4.4349e-01, 1.5942e-02, 5.0625e-02,  ..., 1.1889e-02,\n",
       "            1.2361e-03, 4.3593e-01],\n",
       "           ...,\n",
       "           [4.4214e-01, 3.2768e-03, 8.1812e-03,  ..., 5.7090e-02,\n",
       "            2.4541e-03, 4.3559e-01],\n",
       "           [3.9564e-01, 2.1476e-02, 2.0576e-02,  ..., 3.3113e-02,\n",
       "            2.6663e-02, 3.9208e-01],\n",
       "           [4.4326e-01, 1.9491e-03, 7.8429e-04,  ..., 1.6953e-03,\n",
       "            8.6944e-02, 4.4053e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[4.1120e-02, 1.0956e-01, 6.5788e-02,  ..., 1.1601e-01,\n",
       "            1.0126e-01, 4.0739e-02],\n",
       "           [3.2548e-01, 3.4923e-02, 4.0616e-02,  ..., 2.6153e-02,\n",
       "            3.6910e-03, 3.2213e-01],\n",
       "           [3.1822e-01, 3.9943e-02, 1.7110e-02,  ..., 1.6980e-02,\n",
       "            5.5877e-03, 3.1424e-01],\n",
       "           ...,\n",
       "           [4.9317e-01, 5.5938e-04, 3.0690e-04,  ..., 2.8318e-03,\n",
       "            4.3566e-03, 4.8936e-01],\n",
       "           [4.5793e-01, 7.9626e-03, 7.1378e-03,  ..., 1.5483e-02,\n",
       "            2.1822e-02, 4.5540e-01],\n",
       "           [4.1555e-02, 1.0989e-01, 6.5843e-02,  ..., 1.1542e-01,\n",
       "            1.0105e-01, 4.1171e-02]],\n",
       " \n",
       "          [[4.4587e-02, 3.3572e-02, 6.0334e-02,  ..., 1.3603e-01,\n",
       "            2.4219e-01, 4.4369e-02],\n",
       "           [4.8535e-01, 2.0157e-02, 6.9701e-03,  ..., 4.0497e-04,\n",
       "            6.0358e-04, 4.8044e-01],\n",
       "           [4.4549e-01, 6.5994e-02, 3.4386e-02,  ..., 6.7095e-04,\n",
       "            1.3239e-03, 4.3875e-01],\n",
       "           ...,\n",
       "           [1.5787e-01, 1.8229e-02, 7.8358e-03,  ..., 9.8154e-03,\n",
       "            8.2203e-03, 1.5449e-01],\n",
       "           [1.4511e-01, 3.5189e-02, 2.2744e-02,  ..., 2.9217e-02,\n",
       "            4.7360e-02, 1.4272e-01],\n",
       "           [4.4703e-02, 3.3379e-02, 6.0043e-02,  ..., 1.3702e-01,\n",
       "            2.4263e-01, 4.4484e-02]],\n",
       " \n",
       "          [[1.6944e-01, 3.7057e-02, 2.3734e-02,  ..., 4.7385e-02,\n",
       "            2.5237e-01, 1.6619e-01],\n",
       "           [3.4206e-01, 9.6887e-03, 1.2336e-01,  ..., 6.0542e-03,\n",
       "            8.7858e-03, 3.3832e-01],\n",
       "           [3.6341e-01, 5.1030e-03, 7.5189e-03,  ..., 7.5258e-04,\n",
       "            3.7137e-03, 3.5974e-01],\n",
       "           ...,\n",
       "           [4.8866e-01, 2.6738e-04, 3.1088e-04,  ..., 9.8990e-04,\n",
       "            1.7911e-02, 4.8671e-01],\n",
       "           [4.0732e-01, 3.8137e-02, 9.6832e-03,  ..., 4.4490e-02,\n",
       "            2.2998e-02, 4.0793e-01],\n",
       "           [1.7047e-01, 3.6989e-02, 2.3646e-02,  ..., 4.6833e-02,\n",
       "            2.5233e-01, 1.6721e-01]]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"./download_models/hfl/rbt3\", output_attentions=True)\n",
    "output = model(**inputs)\n",
    "output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6804,  0.6664,  0.7170,  ..., -0.4102,  0.7839, -0.0262],\n",
       "         [-0.7378, -0.2748,  0.5034,  ..., -0.1359, -0.4331, -0.5874],\n",
       "         [-0.0212,  0.5642,  0.1032,  ..., -0.3617,  0.4646, -0.4747],\n",
       "         ...,\n",
       "         [ 0.0853,  0.6679, -0.1757,  ..., -0.0942,  0.4664,  0.2925],\n",
       "         [ 0.3336,  0.3224, -0.3355,  ..., -0.3262,  0.2532, -0.2507],\n",
       "         [ 0.6761,  0.6688,  0.7154,  ..., -0.4083,  0.7824, -0.0224]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with model head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "cls_model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0079, -0.1345,  0.6314, -0.4475,  0.4787,  0.4542,  0.4333,  0.9155,\n",
       "          0.9905,  0.3479]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
