{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:8889\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:8889\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such files: './datasets/alpaca-zh/dataset_info.json', nor './datasets/alpaca-zh/state.json' found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dean/Github/LLM-Model/Huggingface/PEFT/BitFit.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6f63616c2d5043227d/home/dean/Github/LLM-Model/Huggingface/PEFT/BitFit.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ds \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mload_from_disk(\u001b[39m'\u001b[39;49m\u001b[39m./datasets/alpaca-zh\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/datasets/arrow_dataset.py:1668\u001b[0m, in \u001b[0;36mDataset.load_from_disk\u001b[0;34m(dataset_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dataset_info_is_file \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dataset_state_is_file:\n\u001b[1;32m   1667\u001b[0m     \u001b[39mif\u001b[39;00m dataset_dict_is_file:\n\u001b[0;32m-> 1668\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1669\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such files: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_info_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, nor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_state_json_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1670\u001b[0m         )\n\u001b[1;32m   1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1672\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such files: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_info_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, nor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_state_json_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m found. Expected to load a `Dataset` object but provided path is not a `Dataset`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1673\u001b[0m     )\n\u001b[1;32m   1674\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dataset_info_is_file:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such files: './datasets/alpaca-zh/dataset_info.json', nor './datasets/alpaca-zh/state.json' found. Expected to load a `Dataset` object, but got a `DatasetDict`. Please use either `datasets.load_from_disk` or `DatasetDict.load_from_disk` instead."
     ]
    }
   ],
   "source": [
    "ds = Dataset.load_from_disk('./datasets/alpaca-zh', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 48818/48818 [00:00<00:00, 2159092.45 examples/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
