{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:8889\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:8889\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Import\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = load_dataset(\"c3\",\"dialog\")\n",
    "# datasets.save_to_disk(\"./datasets/c3/dialog\")\n",
    "\n",
    "datasets = load_from_disk(\"./datasets/c3/dialog\")\n",
    "\n",
    "def extract_choice(example):\n",
    "    example[\"choice\"] = example[\"questions\"][\"choice\"][0]\n",
    "    example[\"answer\"] = example[\"questions\"][\"answer\"][0]\n",
    "    example[\"question\"] = example[\"questions\"][\"question\"][0]\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(extract_choice, batch_size=True, remove_columns=[\"questions\"])\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.pop(\"test\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 data preprocessing\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
    "\n",
    "def process_func(example):\n",
    "    context = []\n",
    "    question_choice = []\n",
    "    label = []\n",
    "    for idx in range(len(example[\"documents\"])):\n",
    "        ctx = \"\\n\".join(example[\"documents\"][idx])\n",
    "        quextion = example[\"question\"][idx]\n",
    "        choices = example[\"choice\"][idx]\n",
    "        for choice in choices:\n",
    "            context.append(ctx)\n",
    "            question_choice.append(quextion + \" \" + choice)\n",
    "        if len(choices) < 4:\n",
    "            for _ in range(4 - len(choices)):\n",
    "                context.append(ctx)\n",
    "                question_choice.append(quextion + \" \" + \"无法确定\")\n",
    "        label.append(choices.index(example[\"answer\"][idx]))\n",
    "    \n",
    "    tokenized_examples = tokenizer(context, question_choice, truncation=\"only_first\",max_length=256, padding=\"max_length\")\n",
    "    tokenized_examples = {k: [v[i: i+4] for i in range(0, len(v), 4)] for k,v in tokenized_examples.items()} \n",
    "    tokenized_examples[\"label\"] = label\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_c3 = datasets.map(process_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Create model\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"hfl/chinese-macbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Evaluation\n",
    "import numpy as np\n",
    "accuracy =  evaluate.load(\"accuracy\")\n",
    "\n",
    "def comput_metric(pred):\n",
    "    predictions, references = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Train args\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./models/mc\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_c3[\"train\"],\n",
    "    eval_dataset=tokenized_c3[\"validation\"],\n",
    "    compute_metrics=comput_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Prediction\n",
    "class MultipleChoicePipeline:\n",
    "    \n",
    "    def __init__(self, model, tokenizer) -> None:\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "        \n",
    "    def preprocess(self, context, question, choices):\n",
    "        cs, qcs = [], []\n",
    "        for c in choices:\n",
    "            cs.append(context)\n",
    "            qcs.append(question + \" \" + c)\n",
    "        return tokenizer(cs, qcs, truncation=\"only_first\", max_length=256, return_tensors=\"pt\")\n",
    "    \n",
    "        \n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs).logits\n",
    "    \n",
    "    def postprocess(self, logits, choices):\n",
    "        return choices[logits.argmax(dim=-1).cpu().item()]\n",
    "    \n",
    "    def __call__(self, context, question, choices):\n",
    "        inputs = self.preprocess(context, question, choices)\n",
    "        logits = self.predict(inputs)\n",
    "        return self.postprocess(logits, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MultipleChoicePipeline(model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\n",
    "    context=\"我是一个首尔人，我爱我的祖国\",\n",
    "    question=\"我是哪国人？\",\n",
    "    choices=[\"中国人\", \"美国人\", \"日本人\", \"韩国人\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
